{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# GENERAL: Strategic Game AI Training\n",
                "\n",
                "GPU-accelerated training using AlphaZero-style RL. Optimizations enabled for Colab (T4) and Local (RTX) environments.\n",
                "\n",
                "This notebook uses the optimized `GenGameAI` codebase with:\n",
                "- **Non-blocking Inference** (Asyncio + ThreadPool)\n",
                "- **Efficient Data Loading** (DataLoader with pinned memory)\n",
                "- **Auto-Configuration** (Detects GPU VRAM and CPU cores)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_header"
            },
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "!git clone https://github.com/Tanish-2006/Generals.git\n",
                "%cd Generals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "!python3.11 -m pip install torch numpy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "e:\\Projects\\GenGameAI\n"
                    ]
                }
            ],
            "source": [
                "%cd .."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config_header"
            },
            "source": [
                "## 2. Configuration & Hardware Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "verify_config"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
                        "VRAM: 8.59 GB\n",
                        "\n",
                        "Auto-Detected Configuration:\n",
                        "  Workers: 0\n",
                        "  Batch Size: 64\n",
                        "  Games/Iter: 16\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "import torch\n",
                "from config import TRAINING\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"WARNING: No GPU detected.\")\n",
                "\n",
                "print(\"\\nAuto-Detected Configuration:\")\n",
                "print(f\"  Workers: {TRAINING.num_workers}\")\n",
                "print(f\"  Batch Size: {TRAINING.batch_size}\")\n",
                "print(f\"  Games/Iter: {TRAINING.games_per_iter}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "upload_header"
            },
            "source": [
                "## 3. Upload Previous Model (Optional)\n",
                "If you have a `model_latest.pth` or `model_old.pth` from a previous run, upload it here to resume training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "upload_model"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "from pathlib import Path\n",
                "\n",
                "CHECKPOINT_DIR = Path(\"data/checkpoints\")\n",
                "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"Upload model_latest.pth or model_old.pth if you have one:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "for filename in uploaded.keys():\n",
                "    target_path = CHECKPOINT_DIR / filename\n",
                "    with open(target_path, 'wb') as f:\n",
                "        f.write(uploaded[filename])\n",
                "    print(f\"Saved {filename} to {target_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "training_header"
            },
            "source": [
                "## 4. Training Loop\n",
                "Runs the main optimized training loop. Supports resuming if models exist."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_training"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[main] Found 12 replay batches. Resuming from iteration 13.\n",
                        "[Trainer] Using device: cuda\n",
                        "[Trainer] AMP enabled for faster training\n",
                        "[Trainer] JIT compilation skipped on Windows (Triton not supported)\n",
                        "[main] Resuming with Best Model (model_old.pth)\n",
                        "[main] Successfully loaded model from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_old.pth\n",
                        "[InferenceServer] Started on cuda:0 with batch_size=16\n",
                        "\n",
                        "============================================================\n",
                        "[main] ITERATION 13 - self-play 16 games\n",
                        "============================================================\n",
                        "[main] Generating 16 games concurrently...\n",
                        "[ReplayBuffer] Saved: E:\\Projects\\GenGameAI\\data\\replay\\batch_0013.npz\n",
                        "[main] Loading replay data to train\n",
                        "[ReplayBuffer] Loaded 13 batches\n",
                        "[main] Training for 3 epochs...\n",
                        "\n",
                        "[Trainer] Training on 24308 samples\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 1/3\n",
                        "============================================================\n",
                        "  Batch   0/379 | Loss: 6.3548 | Policy: 6.1464 | Value: 0.2084\n",
                        "  Batch  20/379 | Loss: 5.0525 | Policy: 4.7259 | Value: 0.3267\n",
                        "  Batch  40/379 | Loss: 4.6946 | Policy: 4.3036 | Value: 0.3910\n",
                        "  Batch  60/379 | Loss: 4.6740 | Policy: 4.3808 | Value: 0.2931\n",
                        "  Batch  80/379 | Loss: 4.2176 | Policy: 3.9648 | Value: 0.2528\n",
                        "  Batch 100/379 | Loss: 3.8276 | Policy: 3.6190 | Value: 0.2086\n",
                        "  Batch 120/379 | Loss: 4.0636 | Policy: 3.6209 | Value: 0.4426\n",
                        "  Batch 140/379 | Loss: 3.7173 | Policy: 3.5177 | Value: 0.1996\n",
                        "  Batch 160/379 | Loss: 3.8280 | Policy: 3.5682 | Value: 0.2598\n",
                        "  Batch 180/379 | Loss: 3.4354 | Policy: 3.0839 | Value: 0.3515\n",
                        "  Batch 200/379 | Loss: 3.2226 | Policy: 3.0085 | Value: 0.2141\n",
                        "  Batch 220/379 | Loss: 3.3851 | Policy: 3.2232 | Value: 0.1619\n",
                        "  Batch 240/379 | Loss: 3.1425 | Policy: 2.8924 | Value: 0.2501\n",
                        "  Batch 260/379 | Loss: 3.0699 | Policy: 2.7100 | Value: 0.3599\n",
                        "  Batch 280/379 | Loss: 3.1595 | Policy: 2.8594 | Value: 0.3001\n",
                        "  Batch 300/379 | Loss: 2.7426 | Policy: 2.5808 | Value: 0.1618\n",
                        "  Batch 320/379 | Loss: 2.8172 | Policy: 2.5869 | Value: 0.2303\n",
                        "  Batch 340/379 | Loss: 2.3935 | Policy: 2.1559 | Value: 0.2376\n",
                        "  Batch 360/379 | Loss: 2.6814 | Policy: 2.5070 | Value: 0.1744\n",
                        "\n",
                        "Epoch 1 Average Loss: 3.6025\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 2/3\n",
                        "============================================================\n",
                        "  Batch   0/379 | Loss: 2.1441 | Policy: 1.9111 | Value: 0.2330\n",
                        "  Batch  20/379 | Loss: 1.7985 | Policy: 1.7478 | Value: 0.0508\n",
                        "  Batch  40/379 | Loss: 1.9896 | Policy: 1.7966 | Value: 0.1930\n",
                        "  Batch  60/379 | Loss: 1.8771 | Policy: 1.7857 | Value: 0.0914\n",
                        "  Batch  80/379 | Loss: 1.9731 | Policy: 1.7401 | Value: 0.2331\n",
                        "  Batch 100/379 | Loss: 2.2012 | Policy: 2.0656 | Value: 0.1356\n",
                        "  Batch 120/379 | Loss: 1.9258 | Policy: 1.6502 | Value: 0.2757\n",
                        "  Batch 140/379 | Loss: 1.8278 | Policy: 1.6705 | Value: 0.1573\n",
                        "  Batch 160/379 | Loss: 1.8219 | Policy: 1.6645 | Value: 0.1574\n",
                        "  Batch 180/379 | Loss: 2.0167 | Policy: 1.7923 | Value: 0.2244\n",
                        "  Batch 200/379 | Loss: 2.0027 | Policy: 1.8173 | Value: 0.1854\n",
                        "  Batch 220/379 | Loss: 2.0371 | Policy: 1.7736 | Value: 0.2635\n",
                        "  Batch 240/379 | Loss: 1.7743 | Policy: 1.6628 | Value: 0.1115\n",
                        "  Batch 260/379 | Loss: 1.7459 | Policy: 1.4517 | Value: 0.2942\n",
                        "  Batch 280/379 | Loss: 2.5227 | Policy: 2.2795 | Value: 0.2432\n",
                        "  Batch 300/379 | Loss: 1.7722 | Policy: 1.6794 | Value: 0.0928\n",
                        "  Batch 320/379 | Loss: 1.9594 | Policy: 1.7281 | Value: 0.2313\n",
                        "  Batch 340/379 | Loss: 1.5013 | Policy: 1.3804 | Value: 0.1209\n",
                        "  Batch 360/379 | Loss: 1.8508 | Policy: 1.7343 | Value: 0.1164\n",
                        "\n",
                        "Epoch 2 Average Loss: 1.8981\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 3/3\n",
                        "============================================================\n",
                        "  Batch   0/379 | Loss: 1.4026 | Policy: 1.2317 | Value: 0.1709\n",
                        "  Batch  20/379 | Loss: 1.3494 | Policy: 1.1303 | Value: 0.2191\n",
                        "  Batch  40/379 | Loss: 1.2249 | Policy: 1.0628 | Value: 0.1621\n",
                        "  Batch  60/379 | Loss: 1.2605 | Policy: 1.1808 | Value: 0.0796\n",
                        "  Batch  80/379 | Loss: 1.3641 | Policy: 1.2336 | Value: 0.1305\n",
                        "  Batch 100/379 | Loss: 1.3591 | Policy: 1.2514 | Value: 0.1077\n",
                        "  Batch 120/379 | Loss: 1.4729 | Policy: 1.3073 | Value: 0.1656\n",
                        "  Batch 140/379 | Loss: 1.0689 | Policy: 0.9498 | Value: 0.1191\n",
                        "  Batch 160/379 | Loss: 1.2976 | Policy: 1.2147 | Value: 0.0830\n",
                        "  Batch 180/379 | Loss: 1.4138 | Policy: 1.2242 | Value: 0.1897\n",
                        "  Batch 200/379 | Loss: 1.4225 | Policy: 1.1162 | Value: 0.3063\n",
                        "  Batch 220/379 | Loss: 1.4689 | Policy: 1.2530 | Value: 0.2158\n",
                        "  Batch 240/379 | Loss: 1.1141 | Policy: 0.9945 | Value: 0.1196\n",
                        "  Batch 260/379 | Loss: 1.4774 | Policy: 1.2758 | Value: 0.2016\n",
                        "  Batch 280/379 | Loss: 1.2625 | Policy: 1.0275 | Value: 0.2351\n",
                        "  Batch 300/379 | Loss: 1.2593 | Policy: 1.2002 | Value: 0.0591\n",
                        "  Batch 320/379 | Loss: 1.4383 | Policy: 1.2209 | Value: 0.2174\n",
                        "  Batch 340/379 | Loss: 1.6237 | Policy: 1.4320 | Value: 0.1916\n",
                        "  Batch 360/379 | Loss: 1.0997 | Policy: 0.9774 | Value: 0.1222\n",
                        "\n",
                        "Epoch 3 Average Loss: 1.3564\n",
                        "\n",
                        "[Trainer] Model saved to: E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Reloading InferenceServer with new model weights...\n",
                        "[InferenceServer] Reloaded weights from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Evaluating new model vs previous model (Arena)\n",
                        "[Arena] Using device: cuda\n",
                        "Game 1/10 → Winner: B\n",
                        "Game 2/10 → Winner: A\n",
                        "Game 3/10 → Winner: B\n",
                        "Game 4/10 → Winner: B\n",
                        "Game 5/10 → Winner: A\n",
                        "Game 6/10 → Winner: A\n",
                        "Game 7/10 → Winner: A\n",
                        "Game 8/10 → Winner: B\n",
                        "Game 9/10 → Winner: B\n",
                        "Game 10/10 → Winner: B\n",
                        "\n",
                        "=== Arena Results ===\n",
                        "Model A wins: 4\n",
                        "Model B wins: 6\n",
                        "Win rate A: 0.40\n",
                        "[main] Arena win rate for new model: 0.40\n",
                        "[main] New model rejected. Keeping previous model_old.\n",
                        "\n",
                        "============================================================\n",
                        "[main] ITERATION 14 - self-play 16 games\n",
                        "============================================================\n",
                        "[main] Generating 16 games concurrently...\n",
                        "[ReplayBuffer] Saved: E:\\Projects\\GenGameAI\\data\\replay\\batch_0014.npz\n",
                        "[main] Loading replay data to train\n",
                        "[ReplayBuffer] Loaded 14 batches\n",
                        "[main] Training for 3 epochs...\n",
                        "\n",
                        "[Trainer] Training on 26224 samples\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 1/3\n",
                        "============================================================\n",
                        "  Batch   0/409 | Loss: 1.4970 | Policy: 1.3571 | Value: 0.1400\n",
                        "  Batch  20/409 | Loss: 0.9380 | Policy: 0.7439 | Value: 0.1941\n",
                        "  Batch  40/409 | Loss: 0.9118 | Policy: 0.7220 | Value: 0.1898\n",
                        "  Batch  60/409 | Loss: 1.3761 | Policy: 1.1375 | Value: 0.2386\n",
                        "  Batch  80/409 | Loss: 1.2763 | Policy: 1.0270 | Value: 0.2493\n",
                        "  Batch 100/409 | Loss: 1.1817 | Policy: 1.0174 | Value: 0.1643\n",
                        "  Batch 120/409 | Loss: 0.6845 | Policy: 0.4825 | Value: 0.2020\n",
                        "  Batch 140/409 | Loss: 1.3158 | Policy: 1.1478 | Value: 0.1680\n",
                        "  Batch 160/409 | Loss: 0.8581 | Policy: 0.6369 | Value: 0.2212\n",
                        "  Batch 180/409 | Loss: 0.8954 | Policy: 0.7607 | Value: 0.1347\n",
                        "  Batch 200/409 | Loss: 1.1385 | Policy: 0.8680 | Value: 0.2705\n",
                        "  Batch 220/409 | Loss: 0.7005 | Policy: 0.6086 | Value: 0.0919\n",
                        "  Batch 240/409 | Loss: 1.4426 | Policy: 1.1759 | Value: 0.2667\n",
                        "  Batch 260/409 | Loss: 0.6936 | Policy: 0.5415 | Value: 0.1521\n",
                        "  Batch 280/409 | Loss: 1.0432 | Policy: 0.8013 | Value: 0.2420\n",
                        "  Batch 300/409 | Loss: 0.9778 | Policy: 0.8715 | Value: 0.1063\n",
                        "  Batch 320/409 | Loss: 1.3161 | Policy: 1.1184 | Value: 0.1976\n",
                        "  Batch 340/409 | Loss: 0.7350 | Policy: 0.5557 | Value: 0.1792\n",
                        "  Batch 360/409 | Loss: 1.0414 | Policy: 0.8124 | Value: 0.2290\n",
                        "  Batch 380/409 | Loss: 0.7676 | Policy: 0.5383 | Value: 0.2294\n",
                        "  Batch 400/409 | Loss: 1.0263 | Policy: 0.8177 | Value: 0.2086\n",
                        "\n",
                        "Epoch 1 Average Loss: 1.0288\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 2/3\n",
                        "============================================================\n",
                        "  Batch   0/409 | Loss: 0.8368 | Policy: 0.7048 | Value: 0.1320\n",
                        "  Batch  20/409 | Loss: 0.7247 | Policy: 0.6814 | Value: 0.0433\n",
                        "  Batch  40/409 | Loss: 0.8753 | Policy: 0.6102 | Value: 0.2650\n",
                        "  Batch  60/409 | Loss: 0.4192 | Policy: 0.2997 | Value: 0.1195\n",
                        "  Batch  80/409 | Loss: 0.9118 | Policy: 0.7046 | Value: 0.2073\n",
                        "  Batch 100/409 | Loss: 0.7287 | Policy: 0.6150 | Value: 0.1137\n",
                        "  Batch 120/409 | Loss: 0.4326 | Policy: 0.3404 | Value: 0.0922\n",
                        "  Batch 140/409 | Loss: 0.5226 | Policy: 0.4436 | Value: 0.0790\n",
                        "  Batch 160/409 | Loss: 0.5504 | Policy: 0.4790 | Value: 0.0714\n",
                        "  Batch 180/409 | Loss: 0.8537 | Policy: 0.6506 | Value: 0.2031\n",
                        "  Batch 200/409 | Loss: 0.8513 | Policy: 0.6893 | Value: 0.1620\n",
                        "  Batch 220/409 | Loss: 0.6918 | Policy: 0.5307 | Value: 0.1612\n",
                        "  Batch 240/409 | Loss: 0.7924 | Policy: 0.5140 | Value: 0.2784\n",
                        "  Batch 260/409 | Loss: 0.8004 | Policy: 0.6435 | Value: 0.1569\n",
                        "  Batch 280/409 | Loss: 0.8848 | Policy: 0.7602 | Value: 0.1246\n",
                        "  Batch 300/409 | Loss: 0.9351 | Policy: 0.8031 | Value: 0.1320\n",
                        "  Batch 320/409 | Loss: 0.8403 | Policy: 0.6944 | Value: 0.1460\n",
                        "  Batch 340/409 | Loss: 0.5887 | Policy: 0.4201 | Value: 0.1685\n",
                        "  Batch 360/409 | Loss: 0.5816 | Policy: 0.3542 | Value: 0.2274\n",
                        "  Batch 380/409 | Loss: 0.8979 | Policy: 0.6790 | Value: 0.2188\n",
                        "  Batch 400/409 | Loss: 0.9981 | Policy: 0.6572 | Value: 0.3409\n",
                        "\n",
                        "Epoch 2 Average Loss: 0.7416\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 3/3\n",
                        "============================================================\n",
                        "  Batch   0/409 | Loss: 0.4655 | Policy: 0.3670 | Value: 0.0985\n",
                        "  Batch  20/409 | Loss: 0.6338 | Policy: 0.4829 | Value: 0.1508\n",
                        "  Batch  40/409 | Loss: 0.6023 | Policy: 0.4210 | Value: 0.1813\n",
                        "  Batch  60/409 | Loss: 0.5570 | Policy: 0.4801 | Value: 0.0769\n",
                        "  Batch  80/409 | Loss: 0.7538 | Policy: 0.5721 | Value: 0.1817\n",
                        "  Batch 100/409 | Loss: 0.4703 | Policy: 0.3542 | Value: 0.1161\n",
                        "  Batch 120/409 | Loss: 0.4641 | Policy: 0.3182 | Value: 0.1459\n",
                        "  Batch 140/409 | Loss: 0.3699 | Policy: 0.1915 | Value: 0.1784\n",
                        "  Batch 160/409 | Loss: 0.5773 | Policy: 0.3886 | Value: 0.1887\n",
                        "  Batch 180/409 | Loss: 0.4766 | Policy: 0.2536 | Value: 0.2230\n",
                        "  Batch 200/409 | Loss: 0.5991 | Policy: 0.3018 | Value: 0.2973\n",
                        "  Batch 220/409 | Loss: 0.5035 | Policy: 0.3810 | Value: 0.1225\n",
                        "  Batch 240/409 | Loss: 0.5611 | Policy: 0.4806 | Value: 0.0806\n",
                        "  Batch 260/409 | Loss: 0.5169 | Policy: 0.3474 | Value: 0.1695\n",
                        "  Batch 280/409 | Loss: 0.4627 | Policy: 0.3961 | Value: 0.0666\n",
                        "  Batch 300/409 | Loss: 0.4923 | Policy: 0.3558 | Value: 0.1365\n",
                        "  Batch 320/409 | Loss: 0.4466 | Policy: 0.3696 | Value: 0.0770\n",
                        "  Batch 340/409 | Loss: 0.8481 | Policy: 0.6146 | Value: 0.2335\n",
                        "  Batch 360/409 | Loss: 0.5800 | Policy: 0.4522 | Value: 0.1278\n",
                        "  Batch 380/409 | Loss: 0.3420 | Policy: 0.2770 | Value: 0.0650\n",
                        "  Batch 400/409 | Loss: 0.4182 | Policy: 0.3439 | Value: 0.0743\n",
                        "\n",
                        "Epoch 3 Average Loss: 0.5329\n",
                        "\n",
                        "[Trainer] Model saved to: E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Reloading InferenceServer with new model weights...\n",
                        "[InferenceServer] Reloaded weights from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Evaluating new model vs previous model (Arena)\n",
                        "[Arena] Using device: cuda\n",
                        "Game 1/10 → Winner: A\n",
                        "Game 2/10 → Winner: A\n",
                        "Game 3/10 → Winner: A\n",
                        "Game 4/10 → Winner: A\n",
                        "Game 5/10 → Winner: A\n"
                    ]
                }
            ],
            "source": [
                "from main import main_loop\n",
                "\n",
                "await main_loop(max_iterations=20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download_header"
            },
            "source": [
                "## 5. Download Trained Model\n",
                "Download the latest model checkpoint."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_model"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "from pathlib import Path\n",
                "\n",
                "model_path = Path(\"data/checkpoints/model_latest.pth\")\n",
                "if model_path.exists():\n",
                "    files.download(str(model_path))\n",
                "    print(f\"Downloaded: {model_path}\")\n",
                "else:\n",
                "    print(\"No model found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "monitoring_header"
            },
            "source": [
                "## 6. Monitoring (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "training_status"
            },
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "CHECKPOINT_DIR = Path(\"data/checkpoints\")\n",
                "REPLAY_DIR = Path(\"data/replay\")\n",
                "\n",
                "def show_training_status():\n",
                "    print(\"=\" * 50)\n",
                "    print(\"TRAINING STATUS\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    if CHECKPOINT_DIR.exists():\n",
                "        checkpoints = list(CHECKPOINT_DIR.glob(\"*.pth\"))\n",
                "        print(f\"\\nCheckpoints: {len(checkpoints)}\")\n",
                "        for cp in checkpoints:\n",
                "            size_mb = cp.stat().st_size / (1024 * 1024)\n",
                "            print(f\"  - {cp.name}: {size_mb:.2f} MB\")\n",
                "    \n",
                "    if REPLAY_DIR.exists():\n",
                "        replays = list(REPLAY_DIR.glob(\"*.npz\"))\n",
                "        print(f\"\\nReplay batches: {len(replays)}\")\n",
                "        if replays:\n",
                "            total_size = sum(r.stat().st_size for r in replays) / (1024 * 1024)\n",
                "            print(f\"  Total size: {total_size:.2f} MB\")\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        print(\"\\nGPU Memory:\")\n",
                "        print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
                "        print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
                "\n",
                "show_training_status()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
