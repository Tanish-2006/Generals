{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# GENERAL: Strategic Game AI Training\n",
                "\n",
                "GPU-accelerated training using AlphaZero-style RL. Optimizations enabled for Colab (T4) and Local (RTX) environments.\n",
                "\n",
                "This notebook uses the optimized `GenGameAI` codebase with:\n",
                "- **Non-blocking Inference** (Asyncio + ThreadPool)\n",
                "- **Efficient Data Loading** (DataLoader with pinned memory)\n",
                "- **Auto-Configuration** (Detects GPU VRAM and CPU cores)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_header"
            },
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "!git clone https://github.com/Tanish-2006/Generals.git\n",
                "%cd Generals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "!python3.11 -m pip install torch numpy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd .."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config_header"
            },
            "source": [
                "## 2. Configuration & Hardware Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "verify_config"
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "import torch\n",
                "from config import TRAINING\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"WARNING: No GPU detected.\")\n",
                "\n",
                "print(\"\\nAuto-Detected Configuration:\")\n",
                "print(f\"  Workers: {TRAINING.num_workers}\")\n",
                "print(f\"  Batch Size: {TRAINING.batch_size}\")\n",
                "print(f\"  Games/Iter: {TRAINING.games_per_iter}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "upload_header"
            },
            "source": [
                "## 3. Upload Previous Model (Optional)\n",
                "If you have a `model_latest.pth` or `model_old.pth` from a previous run, upload it here to resume training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "upload_model"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "from pathlib import Path\n",
                "\n",
                "CHECKPOINT_DIR = Path(\"data/checkpoints\")\n",
                "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"Upload model_latest.pth or model_old.pth if you have one:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "for filename in uploaded.keys():\n",
                "    target_path = CHECKPOINT_DIR / filename\n",
                "    with open(target_path, 'wb') as f:\n",
                "        f.write(uploaded[filename])\n",
                "    print(f\"Saved {filename} to {target_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "training_header"
            },
            "source": [
                "## 4. Training Loop\n",
                "Runs the main optimized training loop. Supports resuming if models exist."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_training"
            },
            "outputs": [],
            "source": [
                "from main import main_loop\n",
                "\n",
                "await main_loop(max_iterations=20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download_header"
            },
            "source": [
                "## 5. Download Trained Model\n",
                "Download the latest model checkpoint."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_model"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "from pathlib import Path\n",
                "\n",
                "model_path = Path(\"data/checkpoints/model_latest.pth\")\n",
                "if model_path.exists():\n",
                "    files.download(str(model_path))\n",
                "    print(f\"Downloaded: {model_path}\")\n",
                "else:\n",
                "    print(\"No model found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "monitoring_header"
            },
            "source": [
                "## 6. Monitoring (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "training_status"
            },
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "CHECKPOINT_DIR = Path(\"data/checkpoints\")\n",
                "REPLAY_DIR = Path(\"data/replay\")\n",
                "\n",
                "def show_training_status():\n",
                "    print(\"=\" * 50)\n",
                "    print(\"TRAINING STATUS\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    if CHECKPOINT_DIR.exists():\n",
                "        checkpoints = list(CHECKPOINT_DIR.glob(\"*.pth\"))\n",
                "        print(f\"\\nCheckpoints: {len(checkpoints)}\")\n",
                "        for cp in checkpoints:\n",
                "            size_mb = cp.stat().st_size / (1024 * 1024)\n",
                "            print(f\"  - {cp.name}: {size_mb:.2f} MB\")\n",
                "    \n",
                "    if REPLAY_DIR.exists():\n",
                "        replays = list(REPLAY_DIR.glob(\"*.npz\"))\n",
                "        print(f\"\\nReplay batches: {len(replays)}\")\n",
                "        if replays:\n",
                "            total_size = sum(r.stat().st_size for r in replays) / (1024 * 1024)\n",
                "            print(f\"  Total size: {total_size:.2f} MB\")\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        print(\"\\nGPU Memory:\")\n",
                "        print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
                "        print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
                "\n",
                "show_training_status()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
