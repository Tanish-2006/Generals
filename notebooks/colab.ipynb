{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "header"
            },
            "source": [
                "# GENERAL: Strategic Game AI Training\n",
                "\n",
                "GPU-accelerated training using AlphaZero-style RL. Optimizations enabled for Colab (T4) and Local (RTX) environments.\n",
                "\n",
                "This notebook uses the optimized `GenGameAI` codebase with:\n",
                "- **Non-blocking Inference** (Asyncio + ThreadPool)\n",
                "- **Efficient Data Loading** (DataLoader with pinned memory)\n",
                "- **Auto-Configuration** (Detects GPU VRAM and CPU cores)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "setup_header"
            },
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "!git clone https://github.com/Tanish-2006/Generals.git\n",
                "%cd Generals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install_deps"
            },
            "outputs": [],
            "source": [
                "!python3.11 -m pip install torch numpy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "e:\\Projects\\GenGameAI\n"
                    ]
                }
            ],
            "source": [
                "%cd .."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "config_header"
            },
            "source": [
                "## 2. Configuration & Hardware Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "verify_config"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
                        "VRAM: 8.59 GB\n",
                        "\n",
                        "Auto-Detected Configuration:\n",
                        "  Workers: 0\n",
                        "  Batch Size: 64\n",
                        "  Games/Iter: 16\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "import torch\n",
                "from config import TRAINING, NETWORK\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"WARNING: No GPU detected.\")\n",
                "\n",
                "print(\"\\nAuto-Detected Configuration:\")\n",
                "print(f\"  Workers: {TRAINING.num_workers}\")\n",
                "print(f\"  Batch Size: {TRAINING.batch_size}\")\n",
                "print(f\"  Games/Iter: {TRAINING.games_per_iter}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "upload_header"
            },
            "source": [
                "## 3. Upload Previous Model (Optional)\n",
                "If you have a `model_latest.pth` or `model_old.pth` from a previous run, upload it here to resume training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "upload_model"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "from pathlib import Path\n",
                "\n",
                "CHECKPOINT_DIR = Path(\"data/checkpoints\")\n",
                "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"Upload model_latest.pth or model_old.pth if you have one:\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "for filename in uploaded.keys():\n",
                "    target_path = CHECKPOINT_DIR / filename\n",
                "    with open(target_path, 'wb') as f:\n",
                "        f.write(uploaded[filename])\n",
                "    print(f\"Saved {filename} to {target_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "training_header"
            },
            "source": [
                "## 4. Training Loop\n",
                "Runs the main optimized training loop. Supports resuming if models exist."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run_training"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[main] Found 1 replay batches. Resuming from iteration 2.\n",
                        "[Trainer] Using device: cuda\n",
                        "[Trainer] AMP enabled for faster training\n",
                        "[Trainer] JIT compilation skipped on Windows (Triton not supported)\n",
                        "[main] Resuming with Best Model (model_old.pth)\n",
                        "[main] Successfully loaded model from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_old.pth\n",
                        "[InferenceServer] Started on cuda:0 with batch_size=16\n",
                        "\n",
                        "============================================================\n",
                        "[main] ITERATION 2 - self-play 16 games\n",
                        "============================================================\n",
                        "[main] Generating 16 games concurrently...\n",
                        "[ReplayBuffer] Saved: E:\\Projects\\GenGameAI\\data\\replay\\batch_0002.npz\n",
                        "[main] Loading replay data to train\n",
                        "[ReplayBuffer] Loaded 2 batches\n",
                        "[main] Training for 3 epochs...\n",
                        "\n",
                        "[Trainer] Training on 3560 samples\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 1/3\n",
                        "============================================================\n",
                        "  Batch   0/55 | Loss: 9.9759 | Policy: 8.9100 | Value: 1.0659\n",
                        "  Batch  20/55 | Loss: 8.9699 | Policy: 8.3899 | Value: 0.5799\n",
                        "  Batch  40/55 | Loss: 8.6113 | Policy: 8.0985 | Value: 0.5128\n",
                        "\n",
                        "Epoch 1 Average Loss: 9.0051\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 2/3\n",
                        "============================================================\n",
                        "  Batch   0/55 | Loss: 7.6151 | Policy: 7.2907 | Value: 0.3244\n",
                        "  Batch  20/55 | Loss: 7.5845 | Policy: 7.4293 | Value: 0.1552\n",
                        "  Batch  40/55 | Loss: 7.0510 | Policy: 6.8912 | Value: 0.1599\n",
                        "\n",
                        "Epoch 2 Average Loss: 7.3963\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 3/3\n",
                        "============================================================\n",
                        "  Batch   0/55 | Loss: 6.8447 | Policy: 6.7000 | Value: 0.1447\n",
                        "  Batch  20/55 | Loss: 6.6273 | Policy: 6.3803 | Value: 0.2470\n",
                        "  Batch  40/55 | Loss: 6.6025 | Policy: 6.5529 | Value: 0.0495\n",
                        "\n",
                        "Epoch 3 Average Loss: 6.7514\n",
                        "\n",
                        "[Trainer] Model saved to: E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Reloading InferenceServer with new model weights...\n",
                        "[InferenceServer] Reloaded weights from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Evaluating new model vs previous model (Arena)\n",
                        "[Arena] Using device: cuda\n",
                        "Game 1/10 → Winner: A\n",
                        "Game 2/10 → Winner: A\n",
                        "Game 3/10 → Winner: A\n",
                        "Game 4/10 → Winner: B\n",
                        "Game 5/10 → Winner: A\n",
                        "Game 6/10 → Winner: A\n",
                        "Game 7/10 → Winner: A\n",
                        "Game 8/10 → Winner: A\n",
                        "Game 9/10 → Winner: A\n",
                        "Game 10/10 → Winner: A\n",
                        "\n",
                        "=== Arena Results ===\n",
                        "Model A wins: 9\n",
                        "Model B wins: 1\n",
                        "Win rate A: 0.90\n",
                        "[main] Arena win rate for new model: 0.90\n",
                        "[main] New model accepted! Copying model_latest -> model_old\n",
                        "\n",
                        "============================================================\n",
                        "[main] ITERATION 3 - self-play 16 games\n",
                        "============================================================\n",
                        "[main] Generating 16 games concurrently...\n",
                        "[ReplayBuffer] Saved: E:\\Projects\\GenGameAI\\data\\replay\\batch_0003.npz\n",
                        "[main] Loading replay data to train\n",
                        "[ReplayBuffer] Loaded 3 batches\n",
                        "[main] Training for 3 epochs...\n",
                        "\n",
                        "[Trainer] Training on 5505 samples\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 1/3\n",
                        "============================================================\n",
                        "  Batch   0/86 | Loss: 6.8869 | Policy: 6.4476 | Value: 0.4394\n",
                        "  Batch  20/86 | Loss: 6.9015 | Policy: 6.5837 | Value: 0.3178\n",
                        "  Batch  40/86 | Loss: 6.7993 | Policy: 6.5909 | Value: 0.2084\n",
                        "  Batch  60/86 | Loss: 6.9259 | Policy: 6.5608 | Value: 0.3652\n",
                        "  Batch  80/86 | Loss: 7.0742 | Policy: 6.6703 | Value: 0.4039\n",
                        "\n",
                        "Epoch 1 Average Loss: 6.7479\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 2/3\n",
                        "============================================================\n",
                        "  Batch   0/86 | Loss: 5.9133 | Policy: 5.7117 | Value: 0.2015\n",
                        "  Batch  20/86 | Loss: 5.5725 | Policy: 5.3975 | Value: 0.1750\n",
                        "  Batch  40/86 | Loss: 5.8993 | Policy: 5.6821 | Value: 0.2172\n",
                        "  Batch  60/86 | Loss: 5.1445 | Policy: 4.7260 | Value: 0.4185\n",
                        "  Batch  80/86 | Loss: 5.1313 | Policy: 5.0189 | Value: 0.1124\n",
                        "\n",
                        "Epoch 2 Average Loss: 5.5716\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 3/3\n",
                        "============================================================\n",
                        "  Batch   0/86 | Loss: 4.1430 | Policy: 4.1229 | Value: 0.0200\n",
                        "  Batch  20/86 | Loss: 3.3611 | Policy: 3.2009 | Value: 0.1602\n",
                        "  Batch  40/86 | Loss: 3.3917 | Policy: 3.3697 | Value: 0.0220\n",
                        "  Batch  60/86 | Loss: 3.3164 | Policy: 3.2207 | Value: 0.0957\n",
                        "  Batch  80/86 | Loss: 3.4891 | Policy: 3.1506 | Value: 0.3385\n",
                        "\n",
                        "Epoch 3 Average Loss: 3.4738\n",
                        "\n",
                        "[Trainer] Model saved to: E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Reloading InferenceServer with new model weights...\n",
                        "[InferenceServer] Reloaded weights from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Evaluating new model vs previous model (Arena)\n",
                        "[Arena] Using device: cuda\n",
                        "Game 1/10 → Winner: B\n",
                        "Game 2/10 → Winner: A\n",
                        "Game 3/10 → Winner: A\n",
                        "Game 4/10 → Winner: B\n",
                        "Game 5/10 → Winner: A\n",
                        "Game 6/10 → Winner: B\n",
                        "Game 7/10 → Winner: A\n",
                        "Game 8/10 → Winner: B\n",
                        "Game 9/10 → Winner: A\n",
                        "Game 10/10 → Winner: B\n",
                        "\n",
                        "=== Arena Results ===\n",
                        "Model A wins: 5\n",
                        "Model B wins: 5\n",
                        "Win rate A: 0.50\n",
                        "[main] Arena win rate for new model: 0.50\n",
                        "[main] New model rejected. Keeping previous model_old.\n",
                        "\n",
                        "============================================================\n",
                        "[main] ITERATION 4 - self-play 16 games\n",
                        "============================================================\n",
                        "[main] Generating 16 games concurrently...\n",
                        "[ReplayBuffer] Saved: E:\\Projects\\GenGameAI\\data\\replay\\batch_0004.npz\n",
                        "[main] Loading replay data to train\n",
                        "[ReplayBuffer] Loaded 4 batches\n",
                        "[main] Training for 3 epochs...\n",
                        "\n",
                        "[Trainer] Training on 7592 samples\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 1/3\n",
                        "============================================================\n",
                        "  Batch   0/118 | Loss: 3.5895 | Policy: 3.1458 | Value: 0.4437\n",
                        "  Batch  20/118 | Loss: 2.6175 | Policy: 2.3569 | Value: 0.2606\n",
                        "  Batch  40/118 | Loss: 3.0108 | Policy: 2.7987 | Value: 0.2121\n",
                        "  Batch  60/118 | Loss: 3.1657 | Policy: 2.8807 | Value: 0.2850\n",
                        "  Batch  80/118 | Loss: 3.1410 | Policy: 2.8066 | Value: 0.3343\n",
                        "  Batch 100/118 | Loss: 2.6165 | Policy: 2.3199 | Value: 0.2966\n",
                        "\n",
                        "Epoch 1 Average Loss: 3.0449\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 2/3\n",
                        "============================================================\n",
                        "  Batch   0/118 | Loss: 1.4273 | Policy: 1.2574 | Value: 0.1698\n",
                        "  Batch  20/118 | Loss: 1.5684 | Policy: 1.4162 | Value: 0.1522\n",
                        "  Batch  40/118 | Loss: 1.3828 | Policy: 1.2729 | Value: 0.1099\n",
                        "  Batch  60/118 | Loss: 1.6222 | Policy: 1.4981 | Value: 0.1240\n",
                        "  Batch  80/118 | Loss: 2.1003 | Policy: 1.8739 | Value: 0.2265\n",
                        "  Batch 100/118 | Loss: 1.3058 | Policy: 1.1912 | Value: 0.1146\n",
                        "\n",
                        "Epoch 2 Average Loss: 1.8382\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 3/3\n",
                        "============================================================\n",
                        "  Batch   0/118 | Loss: 1.1842 | Policy: 0.9396 | Value: 0.2446\n",
                        "  Batch  20/118 | Loss: 1.1741 | Policy: 0.8808 | Value: 0.2933\n",
                        "  Batch  40/118 | Loss: 1.4398 | Policy: 1.2993 | Value: 0.1405\n",
                        "  Batch  60/118 | Loss: 1.0197 | Policy: 0.9535 | Value: 0.0663\n",
                        "  Batch  80/118 | Loss: 1.3400 | Policy: 1.1313 | Value: 0.2087\n",
                        "  Batch 100/118 | Loss: 1.2959 | Policy: 1.1283 | Value: 0.1676\n",
                        "\n",
                        "Epoch 3 Average Loss: 1.1504\n",
                        "\n",
                        "[Trainer] Model saved to: E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Reloading InferenceServer with new model weights...\n",
                        "[InferenceServer] Reloaded weights from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Evaluating new model vs previous model (Arena)\n",
                        "[Arena] Using device: cuda\n",
                        "Game 1/10 → Winner: A\n",
                        "Game 2/10 → Winner: A\n",
                        "Game 3/10 → Winner: A\n",
                        "Game 4/10 → Winner: A\n",
                        "Game 5/10 → Winner: B\n",
                        "Game 6/10 → Winner: B\n",
                        "Game 7/10 → Winner: A\n",
                        "Game 8/10 → Winner: A\n",
                        "Game 9/10 → Winner: B\n",
                        "Game 10/10 → Winner: A\n",
                        "\n",
                        "=== Arena Results ===\n",
                        "Model A wins: 7\n",
                        "Model B wins: 3\n",
                        "Win rate A: 0.70\n",
                        "[main] Arena win rate for new model: 0.70\n",
                        "[main] New model accepted! Copying model_latest -> model_old\n",
                        "\n",
                        "============================================================\n",
                        "[main] ITERATION 5 - self-play 16 games\n",
                        "============================================================\n",
                        "[main] Generating 16 games concurrently...\n",
                        "[ReplayBuffer] Saved: E:\\Projects\\GenGameAI\\data\\replay\\batch_0005.npz\n",
                        "[main] Loading replay data to train\n",
                        "[ReplayBuffer] Loaded 5 batches\n",
                        "[main] Training for 3 epochs...\n",
                        "\n",
                        "[Trainer] Training on 9472 samples\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 1/3\n",
                        "============================================================\n",
                        "  Batch   0/148 | Loss: 1.2286 | Policy: 1.0670 | Value: 0.1617\n",
                        "  Batch  20/148 | Loss: 1.6026 | Policy: 1.4412 | Value: 0.1614\n",
                        "  Batch  40/148 | Loss: 1.6626 | Policy: 1.4993 | Value: 0.1634\n",
                        "  Batch  60/148 | Loss: 1.4874 | Policy: 1.4037 | Value: 0.0837\n",
                        "  Batch  80/148 | Loss: 1.3436 | Policy: 1.2126 | Value: 0.1310\n",
                        "  Batch 100/148 | Loss: 1.3974 | Policy: 1.1322 | Value: 0.2652\n",
                        "  Batch 120/148 | Loss: 1.7626 | Policy: 1.5925 | Value: 0.1701\n",
                        "  Batch 140/148 | Loss: 1.9409 | Policy: 1.5407 | Value: 0.4002\n",
                        "\n",
                        "Epoch 1 Average Loss: 1.6081\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 2/3\n",
                        "============================================================\n",
                        "  Batch   0/148 | Loss: 1.0229 | Policy: 0.8937 | Value: 0.1292\n",
                        "  Batch  20/148 | Loss: 1.1109 | Policy: 0.8794 | Value: 0.2315\n",
                        "  Batch  40/148 | Loss: 1.0025 | Policy: 0.8637 | Value: 0.1389\n",
                        "  Batch  60/148 | Loss: 1.0537 | Policy: 0.8582 | Value: 0.1954\n",
                        "  Batch  80/148 | Loss: 0.8035 | Policy: 0.7546 | Value: 0.0489\n",
                        "  Batch 100/148 | Loss: 0.8822 | Policy: 0.7209 | Value: 0.1613\n",
                        "  Batch 120/148 | Loss: 1.1061 | Policy: 0.9527 | Value: 0.1534\n",
                        "  Batch 140/148 | Loss: 0.7848 | Policy: 0.7083 | Value: 0.0765\n",
                        "\n",
                        "Epoch 2 Average Loss: 0.9549\n",
                        "\n",
                        "============================================================\n",
                        "Epoch 3/3\n",
                        "============================================================\n",
                        "  Batch   0/148 | Loss: 0.4791 | Policy: 0.4616 | Value: 0.0175\n",
                        "  Batch  20/148 | Loss: 0.6452 | Policy: 0.4190 | Value: 0.2261\n",
                        "  Batch  40/148 | Loss: 0.7430 | Policy: 0.6507 | Value: 0.0923\n",
                        "  Batch  60/148 | Loss: 0.7819 | Policy: 0.6671 | Value: 0.1148\n",
                        "  Batch  80/148 | Loss: 0.6800 | Policy: 0.6331 | Value: 0.0469\n",
                        "  Batch 100/148 | Loss: 0.5758 | Policy: 0.5573 | Value: 0.0185\n",
                        "  Batch 120/148 | Loss: 0.7436 | Policy: 0.6358 | Value: 0.1078\n",
                        "  Batch 140/148 | Loss: 0.6329 | Policy: 0.5062 | Value: 0.1267\n",
                        "\n",
                        "Epoch 3 Average Loss: 0.6388\n",
                        "\n",
                        "[Trainer] Model saved to: E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Reloading InferenceServer with new model weights...\n",
                        "[InferenceServer] Reloaded weights from E:\\Projects\\GenGameAI\\data\\checkpoints\\model_latest.pth\n",
                        "[main] Evaluating new model vs previous model (Arena)\n",
                        "[Arena] Using device: cuda\n",
                        "Game 1/10 → Winner: B\n",
                        "Game 2/10 → Winner: B\n",
                        "Game 3/10 → Winner: B\n",
                        "Game 4/10 → Winner: B\n",
                        "Game 5/10 → Winner: B\n",
                        "Game 6/10 → Winner: B\n"
                    ]
                }
            ],
            "source": [
                "from main import main_loop\n",
                "\n",
                "await main_loop(max_iterations=20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "download_header"
            },
            "source": [
                "## 5. Download Trained Model\n",
                "Download the latest model checkpoint."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download_model"
            },
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "from pathlib import Path\n",
                "\n",
                "model_path = Path(\"data/checkpoints/model_latest.pth\")\n",
                "if model_path.exists():\n",
                "    files.download(str(model_path))\n",
                "    print(f\"Downloaded: {model_path}\")\n",
                "else:\n",
                "    print(\"No model found.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "monitoring_header"
            },
            "source": [
                "## 6. Monitoring (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "training_status"
            },
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "CHECKPOINT_DIR = Path(\"data/checkpoints\")\n",
                "REPLAY_DIR = Path(\"data/replay\")\n",
                "\n",
                "def show_training_status():\n",
                "    print(\"=\" * 50)\n",
                "    print(\"TRAINING STATUS\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    if CHECKPOINT_DIR.exists():\n",
                "        checkpoints = list(CHECKPOINT_DIR.glob(\"*.pth\"))\n",
                "        print(f\"\\nCheckpoints: {len(checkpoints)}\")\n",
                "        for cp in checkpoints:\n",
                "            size_mb = cp.stat().st_size / (1024 * 1024)\n",
                "            print(f\"  - {cp.name}: {size_mb:.2f} MB\")\n",
                "    \n",
                "    if REPLAY_DIR.exists():\n",
                "        replays = list(REPLAY_DIR.glob(\"*.npz\"))\n",
                "        print(f\"\\nReplay batches: {len(replays)}\")\n",
                "        if replays:\n",
                "            total_size = sum(r.stat().st_size for r in replays) / (1024 * 1024)\n",
                "            print(f\"  Total size: {total_size:.2f} MB\")\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        print(\"\\nGPU Memory:\")\n",
                "        print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
                "        print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
                "\n",
                "show_training_status()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
