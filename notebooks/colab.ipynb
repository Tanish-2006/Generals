{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# GENERAL: Strategic Game AI Training\n",
                "\n",
                "This notebook provides GPU-accelerated training for the GENERAL project using AlphaZero-style reinforcement learning.\n",
                "\n",
                "## Requirements\n",
                "- Google Colab with GPU runtime (T4, V100, or A100)\n",
                "- Python 3.8+\n",
                "- PyTorch with CUDA support"
            ],
            "metadata": {
                "id": "header"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Environment Setup"
            ],
            "metadata": {
                "id": "setup_header"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "clone_repo"
            },
            "outputs": [],
            "source": [
                "!git clone https://github.com/YOUR_USERNAME/Generals-AI.git\n",
                "%cd Generals-AI/Generals"
            ]
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install torch numpy --quiet"
            ],
            "metadata": {
                "id": "install_deps"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. GPU Verification"
            ],
            "metadata": {
                "id": "gpu_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import torch\n",
                "\n",
                "print(f\"PyTorch Version: {torch.__version__}\")\n",
                "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
                "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"Device Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"WARNING: No GPU detected. Training will be slow.\")\n",
                "    print(\"Go to Runtime -> Change runtime type -> GPU\")"
            ],
            "metadata": {
                "id": "verify_gpu"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Configuration"
            ],
            "metadata": {
                "id": "config_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "TRAINING_CONFIG = {\n",
                "    \"max_iterations\": 100,\n",
                "    \"games_per_iter\": 64,\n",
                "    \"mcts_simulations\": 100,\n",
                "    \"train_epochs\": 5,\n",
                "    \"batch_size\": 64,\n",
                "    \"learning_rate\": 5e-4,\n",
                "    \"eval_games\": 20,\n",
                "    \"acceptance_threshold\": 0.55\n",
                "}\n",
                "\n",
                "print(\"Training Configuration:\")\n",
                "for key, value in TRAINING_CONFIG.items():\n",
                "    print(f\"  {key}: {value}\")"
            ],
            "metadata": {
                "id": "set_config"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. Import and Validate Modules"
            ],
            "metadata": {
                "id": "import_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "from env.generals_env import GeneralsEnv\n",
                "from model.network import GeneralsNet\n",
                "from mcts.mcts import AsyncMCTS\n",
                "from training.train import Trainer\n",
                "from training.replay_buffer import ReplayBuffer\n",
                "from selfplay.selfplay import SelfPlay\n",
                "from evaluate.evaluate import Arena\n",
                "from utils.batched_inference import InferenceServer\n",
                "\n",
                "print(\"All modules imported successfully.\")"
            ],
            "metadata": {
                "id": "import_modules"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "env = GeneralsEnv()\n",
                "state = env.reset()\n",
                "print(f\"Environment initialized. State shape: {state.shape}\")\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "net = GeneralsNet().to(device)\n",
                "param_count = sum(p.numel() for p in net.parameters())\n",
                "print(f\"Network initialized on {device}. Parameters: {param_count:,}\")"
            ],
            "metadata": {
                "id": "validate_components"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. Training Execution"
            ],
            "metadata": {
                "id": "training_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import asyncio\n",
                "import os\n",
                "import shutil\n",
                "import time\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "\n",
                "PROJECT_ROOT = Path(\".\").resolve()\n",
                "CHECKPOINT_DIR = PROJECT_ROOT / \"data\" / \"checkpoints\"\n",
                "REPLAY_DIR = PROJECT_ROOT / \"data\" / \"replay\"\n",
                "\n",
                "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "REPLAY_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(f\"Checkpoint directory: {CHECKPOINT_DIR}\")\n",
                "print(f\"Replay directory: {REPLAY_DIR}\")"
            ],
            "metadata": {
                "id": "setup_dirs"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "async def training_loop(config):\n",
                "    latest_path = CHECKPOINT_DIR / \"model_latest.pth\"\n",
                "    old_path = CHECKPOINT_DIR / \"model_old.pth\"\n",
                "    \n",
                "    trainer = Trainer(\n",
                "        lr=config[\"learning_rate\"],\n",
                "        weight_decay=1e-4,\n",
                "        batch_size=config[\"batch_size\"],\n",
                "        epochs=config[\"train_epochs\"],\n",
                "        checkpoint_dir=str(CHECKPOINT_DIR)\n",
                "    )\n",
                "    \n",
                "    if not old_path.exists():\n",
                "        if latest_path.exists():\n",
                "            shutil.copyfile(latest_path, old_path)\n",
                "            print(\"Copied model_latest to model_old\")\n",
                "        else:\n",
                "            print(\"Creating initial model...\")\n",
                "            states = np.zeros((8, 17, 10, 10), dtype=np.float32)\n",
                "            policies = np.zeros((8, 10003), dtype=np.float32)\n",
                "            policies[:, 0] = 1.0\n",
                "            values = np.zeros((8,), dtype=np.float32)\n",
                "            trainer.train(states, policies, values, save_name=\"model_latest.pth\")\n",
                "            shutil.copyfile(latest_path, old_path)\n",
                "            print(\"Initial model created.\")\n",
                "    \n",
                "    replay = ReplayBuffer(save_dir=str(REPLAY_DIR), max_batches=20)\n",
                "    inference_server = InferenceServer(trainer.net, batch_size=32)\n",
                "    await inference_server.start()\n",
                "    \n",
                "    try:\n",
                "        for iteration in range(1, config[\"max_iterations\"] + 1):\n",
                "            print(f\"\\n{'='*60}\")\n",
                "            print(f\"ITERATION {iteration}/{config['max_iterations']}\")\n",
                "            print(f\"{'='*60}\")\n",
                "            \n",
                "            sp = SelfPlay(\n",
                "                GeneralsEnv,\n",
                "                inference_server,\n",
                "                games_per_iteration=config[\"games_per_iter\"],\n",
                "                mcts_simulations=config[\"mcts_simulations\"],\n",
                "                temperature_threshold=10\n",
                "            )\n",
                "            \n",
                "            print(f\"Generating {config['games_per_iter']} self-play games...\")\n",
                "            start_time = time.time()\n",
                "            states, policies, values = await sp.play_iteration()\n",
                "            elapsed = time.time() - start_time\n",
                "            print(f\"Generated {len(states)} positions in {elapsed:.1f}s\")\n",
                "            \n",
                "            replay.add_game(states, policies, values)\n",
                "            states_all, policies_all, values_all = replay.load_all()\n",
                "            \n",
                "            print(f\"Training on {len(states_all)} total positions...\")\n",
                "            trainer.train(states_all, policies_all, values_all, save_name=\"model_latest.pth\")\n",
                "            \n",
                "            inference_server.reload_model(str(latest_path))\n",
                "            \n",
                "            print(f\"Evaluating new model ({config['eval_games']} games)...\")\n",
                "            arena = Arena(\n",
                "                model_A_path=str(latest_path),\n",
                "                model_B_path=str(old_path),\n",
                "                games=config[\"eval_games\"],\n",
                "                mcts_simulations=config[\"mcts_simulations\"]\n",
                "            )\n",
                "            win_rate = await arena.run()\n",
                "            \n",
                "            if win_rate > config[\"acceptance_threshold\"]:\n",
                "                print(f\"Model ACCEPTED (win rate: {win_rate:.2%})\")\n",
                "                shutil.copyfile(latest_path, old_path)\n",
                "            else:\n",
                "                print(f\"Model REJECTED (win rate: {win_rate:.2%})\")\n",
                "            \n",
                "            time.sleep(0.5)\n",
                "    \n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\nTraining interrupted by user.\")\n",
                "    finally:\n",
                "        await inference_server.stop()\n",
                "        print(\"Training loop completed.\")"
            ],
            "metadata": {
                "id": "training_function"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "await training_loop(TRAINING_CONFIG)"
            ],
            "metadata": {
                "id": "run_training"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6. Download Trained Model"
            ],
            "metadata": {
                "id": "download_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import files\n",
                "\n",
                "model_path = CHECKPOINT_DIR / \"model_latest.pth\"\n",
                "if model_path.exists():\n",
                "    files.download(str(model_path))\n",
                "    print(f\"Downloaded: {model_path}\")\n",
                "else:\n",
                "    print(\"No model found. Run training first.\")"
            ],
            "metadata": {
                "id": "download_model"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7. Training Monitoring"
            ],
            "metadata": {
                "id": "monitoring_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "\n",
                "def show_training_status():\n",
                "    print(\"=\" * 50)\n",
                "    print(\"TRAINING STATUS\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    if CHECKPOINT_DIR.exists():\n",
                "        checkpoints = list(CHECKPOINT_DIR.glob(\"*.pth\"))\n",
                "        print(f\"\\nCheckpoints: {len(checkpoints)}\")\n",
                "        for cp in checkpoints:\n",
                "            size_mb = cp.stat().st_size / (1024 * 1024)\n",
                "            print(f\"  - {cp.name}: {size_mb:.2f} MB\")\n",
                "    \n",
                "    if REPLAY_DIR.exists():\n",
                "        replays = list(REPLAY_DIR.glob(\"*.npz\"))\n",
                "        print(f\"\\nReplay batches: {len(replays)}\")\n",
                "        if replays:\n",
                "            total_size = sum(r.stat().st_size for r in replays) / (1024 * 1024)\n",
                "            print(f\"  Total size: {total_size:.2f} MB\")\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        print(f\"\\nGPU Memory:\")\n",
                "        print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
                "        print(f\"  Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
                "\n",
                "show_training_status()"
            ],
            "metadata": {
                "id": "training_status"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}